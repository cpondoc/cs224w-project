{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8rvGO8rI-ww"
   },
   "source": [
    "# Exploring the Impacts of Architecture and Scale on GNN Performance on Relational Data\n",
    "By: Joseph Guman, Atindra Jha, and Christopher Pondoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook will go over taking the existing Relbench tutorial on training a model and allowing the user to explore different architectures. In particular, we'll look at:\n",
    "- Focusing on entity classification instead of link prediction tasks.\n",
    "- Using different embedding model and GNN architectures.\n",
    "- Transfer learning to apply from one task to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "We'll first set up the necessary packages and load in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21045,
     "status": "ok",
     "timestamp": 1730927176840,
     "user": {
      "displayName": "Christopher Lawrence Marcelino Pondoc",
      "userId": "16749698147323488866"
     },
     "user_tz": 480
    },
    "id": "znRCfU2GMj8P",
    "outputId": "571c7eb1-a8ef-498c-bae2-aa78406fa9ae"
   },
   "outputs": [],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "from src.tasks.tasks import initialize_task\n",
    "\n",
    "# Set up dataset and task, define metrics and loss\n",
    "dataset, task, train_table, val_table, test_table = initialize_task(\"rel-f1\", \"driver-dnf\")\n",
    "\n",
    "out_channels = 1\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "tune_metric = \"roc_auc\"\n",
    "higher_is_better = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do some more bookkeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_frame\n",
    "\n",
    "# Some book keeping\n",
    "from torch_geometric.seed import seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # check that it's cuda if you want it to run in reasonable time!\n",
    "root_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first build a graph out of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/cpondoc/.cache/relbench/rel-f1/db...\n",
      "Done in 0.02 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'standings': {'driverStandingsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'wins': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'constructors': {'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'constructorRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'nationality': <stype.text_embedded: 'text_embedded'>},\n",
       " 'circuits': {'circuitId': <stype.numerical: 'numerical'>,\n",
       "  'circuitRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'location': <stype.text_embedded: 'text_embedded'>,\n",
       "  'country': <stype.text_embedded: 'text_embedded'>,\n",
       "  'lat': <stype.numerical: 'numerical'>,\n",
       "  'lng': <stype.numerical: 'numerical'>,\n",
       "  'alt': <stype.numerical: 'numerical'>},\n",
       " 'qualifying': {'qualifyId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'number': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'constructor_standings': {'constructorStandingsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'wins': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'drivers': {'driverId': <stype.numerical: 'numerical'>,\n",
       "  'driverRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'code': <stype.text_embedded: 'text_embedded'>,\n",
       "  'forename': <stype.text_embedded: 'text_embedded'>,\n",
       "  'surname': <stype.text_embedded: 'text_embedded'>,\n",
       "  'dob': <stype.timestamp: 'timestamp'>,\n",
       "  'nationality': <stype.text_embedded: 'text_embedded'>},\n",
       " 'constructor_results': {'constructorResultsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'races': {'raceId': <stype.numerical: 'numerical'>,\n",
       "  'year': <stype.categorical: 'categorical'>,\n",
       "  'round': <stype.numerical: 'numerical'>,\n",
       "  'circuitId': <stype.numerical: 'numerical'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>,\n",
       "  'time': <stype.timestamp: 'timestamp'>},\n",
       " 'results': {'resultId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'number': <stype.numerical: 'numerical'>,\n",
       "  'grid': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'positionOrder': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'laps': <stype.numerical: 'numerical'>,\n",
       "  'milliseconds': <stype.numerical: 'numerical'>,\n",
       "  'fastestLap': <stype.numerical: 'numerical'>,\n",
       "  'rank': <stype.numerical: 'numerical'>,\n",
       "  'statusId': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relbench.modeling.utils import get_stype_proposal\n",
    "\n",
    "db = dataset.get_db()\n",
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "col_to_stype_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define our text encoding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings.glove import GloveTextEmbedding\n",
    "from src.embeddings.bert import BertTextEmbedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make our primary key and foreign key graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with mean pooling.\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=BertTextEmbedding(device=device), batch_size=128\n",
    ")\n",
    "\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
    "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
    "    cache_dir=os.path.join(\n",
    "        root_dir, f\"rel-f1_materialized_cache\"\n",
    "    ),  # store materialized graph for convenience\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up our data lodaers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "loader_dict = {}\n",
    "\n",
    "for split, table in [\n",
    "    (\"train\", train_table),\n",
    "    (\"val\", val_table),\n",
    "    (\"test\", test_table),\n",
    "]:\n",
    "    table_input = get_node_train_table_input(\n",
    "        table=table,\n",
    "        task=task,\n",
    "    )\n",
    "    entity_table = table_input.nodes[0]\n",
    "    loader_dict[split] = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[\n",
    "            128 for i in range(2)\n",
    "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
    "        time_attr=\"time\",\n",
    "        input_nodes=table_input.nodes,\n",
    "        input_time=table_input.time,\n",
    "        transform=table_input.transform,\n",
    "        batch_size=512,\n",
    "        temporal_strategy=\"uniform\",\n",
    "        shuffle=split == \"train\",\n",
    "        num_workers=0,\n",
    "        persistent_workers=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "import copy\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, ModuleDict\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.typing import NodeType\n",
    "\n",
    "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: HeteroData,\n",
    "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
    "        num_layers: int,\n",
    "        channels: int,\n",
    "        out_channels: int,\n",
    "        aggr: str,\n",
    "        norm: str,\n",
    "        # List of node types to add shallow embeddings to input\n",
    "        shallow_list: List[NodeType] = [],\n",
    "        # ID awareness\n",
    "        id_awareness: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = HeteroEncoder(\n",
    "            channels=channels,\n",
    "            node_to_col_names_dict={\n",
    "                node_type: data[node_type].tf.col_names_dict\n",
    "                for node_type in data.node_types\n",
    "            },\n",
    "            node_to_col_stats=col_stats_dict,\n",
    "        )\n",
    "        self.temporal_encoder = HeteroTemporalEncoder(\n",
    "            node_types=[\n",
    "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
    "            ],\n",
    "            channels=channels,\n",
    "        )\n",
    "        self.gnn = HeteroGraphSAGE(\n",
    "            node_types=data.node_types,\n",
    "            edge_types=data.edge_types,\n",
    "            channels=channels,\n",
    "            aggr=aggr,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.head = MLP(\n",
    "            channels,\n",
    "            out_channels=out_channels,\n",
    "            norm=norm,\n",
    "            num_layers=1,\n",
    "        )\n",
    "        self.embedding_dict = ModuleDict(\n",
    "            {\n",
    "                node: Embedding(data.num_nodes_dict[node], channels)\n",
    "                for node in shallow_list\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.id_awareness_emb = None\n",
    "        if id_awareness:\n",
    "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.encoder.reset_parameters()\n",
    "        self.temporal_encoder.reset_parameters()\n",
    "        self.gnn.reset_parameters()\n",
    "        self.head.reset_parameters()\n",
    "        for embedding in self.embedding_dict.values():\n",
    "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
    "        if self.id_awareness_emb is not None:\n",
    "            self.id_awareness_emb.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: HeteroData,\n",
    "        entity_table: NodeType,\n",
    "    ) -> Tensor:\n",
    "        seed_time = batch[entity_table].seed_time\n",
    "        x_dict = self.encoder(batch.tf_dict)\n",
    "\n",
    "        rel_time_dict = self.temporal_encoder(\n",
    "            seed_time, batch.time_dict, batch.batch_dict\n",
    "        )\n",
    "\n",
    "        for node_type, rel_time in rel_time_dict.items():\n",
    "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
    "\n",
    "        for node_type, embedding in self.embedding_dict.items():\n",
    "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
    "\n",
    "        x_dict = self.gnn(\n",
    "            x_dict,\n",
    "            batch.edge_index_dict,\n",
    "            batch.num_sampled_nodes_dict,\n",
    "            batch.num_sampled_edges_dict,\n",
    "        )\n",
    "\n",
    "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
    "\n",
    "    def forward_dst_readout(\n",
    "        self,\n",
    "        batch: HeteroData,\n",
    "        entity_table: NodeType,\n",
    "        dst_table: NodeType,\n",
    "    ) -> Tensor:\n",
    "        if self.id_awareness_emb is None:\n",
    "            raise RuntimeError(\n",
    "                \"id_awareness must be set True to use forward_dst_readout\"\n",
    "            )\n",
    "        seed_time = batch[entity_table].seed_time\n",
    "        x_dict = self.encoder(batch.tf_dict)\n",
    "        # Add ID-awareness to the root node\n",
    "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
    "\n",
    "        rel_time_dict = self.temporal_encoder(\n",
    "            seed_time, batch.time_dict, batch.batch_dict\n",
    "        )\n",
    "\n",
    "        for node_type, rel_time in rel_time_dict.items():\n",
    "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
    "\n",
    "        for node_type, embedding in self.embedding_dict.items():\n",
    "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
    "\n",
    "        x_dict = self.gnn(\n",
    "            x_dict,\n",
    "            batch.edge_index_dict,\n",
    "        )\n",
    "\n",
    "        return self.head(x_dict[dst_table])\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# if you try out different RelBench tasks you will need to change these\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test Loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train() -> float:\n",
    "    model.train()\n",
    "\n",
    "    loss_accum = count_accum = 0\n",
    "    for batch in tqdm(loader_dict[\"train\"]):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "\n",
    "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.detach().item() * pred.size(0)\n",
    "        count_accum += pred.size(0)\n",
    "\n",
    "    return loss_accum / count_accum\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: NeighborLoader) -> np.ndarray:\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        pred_list.append(pred.detach().cpu())\n",
    "    return torch.cat(pred_list, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.38038626119420005, Val metrics: {'average_precision': np.float64(0.8320271966776239), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.5939047619047619)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.34903314348723863, Val metrics: {'average_precision': np.float64(0.8684545231252181), 'accuracy': 0.5830388692579506, 'f1': np.float64(0.66189111747851), 'roc_auc': np.float64(0.647328798185941)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.3175837788902254, Val metrics: {'average_precision': np.float64(0.8882144858234874), 'accuracy': 0.7544169611307421, 'f1': np.float64(0.8568486096807415), 'roc_auc': np.float64(0.678294784580499)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.310340664509709, Val metrics: {'average_precision': np.float64(0.8884254266850332), 'accuracy': 0.773851590106007, 'f1': np.float64(0.872), 'roc_auc': np.float64(0.677297052154195)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.3055386054751938, Val metrics: {'average_precision': np.float64(0.8910222959804766), 'accuracy': 0.7420494699646644, 'f1': np.float64(0.8479166666666667), 'roc_auc': np.float64(0.6763537414965985)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.3008974842441854, Val metrics: {'average_precision': np.float64(0.887218572318659), 'accuracy': 0.6713780918727915, 'f1': np.float64(0.7720588235294118), 'roc_auc': np.float64(0.6650158730158731)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.2975968336826056, Val metrics: {'average_precision': np.float64(0.8883362619701176), 'accuracy': 0.7491166077738516, 'f1': np.float64(0.8508403361344538), 'roc_auc': np.float64(0.6828299319727891)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.2959435798071737, Val metrics: {'average_precision': np.float64(0.8893077974582537), 'accuracy': 0.6678445229681979, 'f1': np.float64(0.7740384615384616), 'roc_auc': np.float64(0.6780045351473923)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.288865543004142, Val metrics: {'average_precision': np.float64(0.8958534621033442), 'accuracy': 0.7544169611307421, 'f1': np.float64(0.8467475192943771), 'roc_auc': np.float64(0.6958730158730159)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.28812916938977134, Val metrics: {'average_precision': np.float64(0.8924483503596276), 'accuracy': 0.7173144876325088, 'f1': np.float64(0.817351598173516), 'roc_auc': np.float64(0.6878185941043085)}\n",
      "Best Val metrics: {'average_precision': np.float64(0.8959214601585412), 'accuracy': 0.7544169611307421, 'f1': np.float64(0.8467475192943771), 'roc_auc': np.float64(0.6960362811791383)}\n",
      "Best test metrics: {'average_precision': np.float64(0.8504520900815415), 'accuracy': 0.7336182336182336, 'f1': np.float64(0.827966881324747), 'roc_auc': np.float64(0.7344312692138779)}\n"
     ]
    }
   ],
   "source": [
    "state_dict = None\n",
    "best_val_metric = -math.inf if higher_is_better else math.inf\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train()\n",
    "    val_pred = test(loader_dict[\"val\"])\n",
    "    val_metrics = task.evaluate(val_pred, val_table)\n",
    "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
    "\n",
    "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
    "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
    "    ):\n",
    "        best_val_metric = val_metrics[tune_metric]\n",
    "        state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "val_pred = test(loader_dict[\"val\"])\n",
    "val_metrics = task.evaluate(val_pred, val_table)\n",
    "print(f\"Best Val metrics: {val_metrics}\")\n",
    "\n",
    "test_pred = test(loader_dict[\"test\"])\n",
    "test_metrics = task.evaluate(test_pred)\n",
    "print(f\"Best test metrics: {test_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZLbeQ8nLws8bu/8tbPPMT",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
