{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8rvGO8rI-ww"
   },
   "source": [
    "# Exploring the Impacts of Architecture and Scale on GNN Performance on Relational Data\n",
    "By: Joseph Guman, Atindra Jha, and Christopher Pondoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome back to Relbench! In this tutorial, we'll dive a bit deeper into the benchmark + Relational Deep Learning and explore several choices around architecture, scale, and generalizability. In particular, we'll look to answer the following questions:\n",
    "\n",
    "1. Can we train our Relational Deep Learning on one entity classification task and expect strong zero-shot performance on another entity classification task? What happens if we finetune the model?\n",
    "2. How does our choice of using embedding models to generate expressive node features impact our performance on node classification tasks?\n",
    "3. How can we alter and/or extend the architecture of our existing Relational Deep Learning model to improve performance on different tasks?\n",
    "\n",
    "This notebook already assumes you've looked through the tutorials on [loading in data](https://github.com/snap-stanford/relbench/blob/main/tutorials/load_data.ipynb) and [training a model](https://github.com/snap-stanford/relbench/blob/main/tutorials/train_model.ipynb), as our walkthrough uses those guides as a launchpad to explore deeper questions. If you haven't had a chance to look through those notebooks, we suggest starting there first.\n",
    "\n",
    "With all that being said, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Can we generalize?\n",
    "Let's take a look at our first question, which involves looking at whether our Relational Deep Learning model can generalize to other tasks with/without finetuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first start by looking setting up Relbench. As with the other tutorials, we're taking a look at the `rel-f1` dataset and focusing on node classification tasks. We'll begin by training a model on the `driver-dnf` task, which predicts whether a driver will not finish a race in the next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.tasks.tasks import initialize_task, db_to_graph\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch_geometric.seed import seed_everything\n",
    "\n",
    "# Set up dataset and task, define metrics and loss\n",
    "dataset, task, train_table, val_table, test_table = initialize_task(\n",
    "    \"rel-f1\", \"driver-dnf\"\n",
    ")\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "\n",
    "# Set up device\n",
    "seed_everything(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then preprocess all of our Relbench data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/cpondoc/.cache/relbench/rel-f1/db...\n",
      "Done in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from src.embeddings.glove import GloveTextEmbedding\n",
    "\n",
    "# Preprocess the database data and set up our text embedder\n",
    "db, col_to_stype_dict = db_to_graph(dataset)\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=128\n",
    ")\n",
    "\n",
    "# Load in data used to train model\n",
    "root_dir = \"./data\"\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,\n",
    "    text_embedder_cfg=text_embedder_cfg,\n",
    "    cache_dir=os.path.join(root_dir, f\"rel-f1_materialized_cache\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load in the data and have our model set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.loader import get_loader\n",
    "from src.models.rdl.graph_sage import RDLModel\n",
    "\n",
    "# Set up data loader and model\n",
    "loader_dict, entity_table = get_loader(train_table, val_table, test_table, task, data)\n",
    "model = RDLModel(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "\n",
    "# if you try out different RelBench tasks you will need to change these\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize, let's initialize our training run, and evaluate our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.3705387778567783, Val metrics: {'average_precision': np.float64(0.8445602886699217), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.61340589569161)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.339241144625481, Val metrics: {'average_precision': np.float64(0.8824246844093944), 'accuracy': 0.734982332155477, 'f1': np.float64(0.8407643312101911), 'roc_auc': np.float64(0.6783673469387754)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.3132456022974758, Val metrics: {'average_precision': np.float64(0.8877369162685687), 'accuracy': 0.6431095406360424, 'f1': np.float64(0.7548543689320388), 'roc_auc': np.float64(0.6638004535147392)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.3137629664954457, Val metrics: {'average_precision': np.float64(0.8837337509565886), 'accuracy': 0.6501766784452296, 'f1': np.float64(0.7602905569007264), 'roc_auc': np.float64(0.6612789115646259)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.3080086231978641, Val metrics: {'average_precision': np.float64(0.8871259518097254), 'accuracy': 0.7279151943462897, 'f1': np.float64(0.8354700854700855), 'roc_auc': np.float64(0.6681360544217687)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.3053495470402107, Val metrics: {'average_precision': np.float64(0.8891425442587507), 'accuracy': 0.6590106007067138, 'f1': np.float64(0.7721369539551358), 'roc_auc': np.float64(0.6683900226757371)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.30645355049707795, Val metrics: {'average_precision': np.float64(0.8894602472798984), 'accuracy': 0.6519434628975265, 'f1': np.float64(0.7646356033452808), 'roc_auc': np.float64(0.6683537414965987)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.3030857765207616, Val metrics: {'average_precision': np.float64(0.8869164475195142), 'accuracy': 0.6378091872791519, 'f1': np.float64(0.7427854454203262), 'roc_auc': np.float64(0.6694603174603174)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.30097401697110593, Val metrics: {'average_precision': np.float64(0.8869307529447668), 'accuracy': 0.6784452296819788, 'f1': np.float64(0.789838337182448), 'roc_auc': np.float64(0.6650340136054422)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.29329782412802446, Val metrics: {'average_precision': np.float64(0.8873963155089515), 'accuracy': 0.7120141342756183, 'f1': np.float64(0.812428078250863), 'roc_auc': np.float64(0.6679183673469389)}\n",
      "Best val metrics: {'average_precision': np.float64(0.8824005571542506), 'accuracy': 0.734982332155477, 'f1': np.float64(0.8407643312101911), 'roc_auc': np.float64(0.6782947845804989)}\n",
      "Best test metrics: {'average_precision': np.float64(0.8373712236678277), 'accuracy': 0.7264957264957265, 'f1': np.float64(0.8254545454545454), 'roc_auc': np.float64(0.6952617967110721)}\n"
     ]
    }
   ],
   "source": [
    "from src.models.training import eval_model, training_run\n",
    "\n",
    "# Get model after a training run\n",
    "state_dict = training_run(\n",
    "    model, device, optimizer, task, loader_dict, val_table, loss_fn, entity_table\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Evaluate on val and test set\n",
    "eval_model(model, loader_dict, \"val\", task, device, val_table)\n",
    "eval_model(model, loader_dict, \"test\", task, device, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we are able to roughly replicate the results from the [core Relbench paper](https://huggingface.co/spaces/relbench/leaderboard). However, do the results generalize? To do so, let's load in the data for the other entity classification task within `rel-f1` -- `driver-top3` -- and see how we do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test metrics: {'average_precision': np.float64(0.11380641939650467), 'accuracy': 0.19696969696969696, 'f1': np.float64(0.22781456953642384), 'roc_auc': np.float64(0.23915003135451504)}\n"
     ]
    }
   ],
   "source": [
    "# Reuse functions to set up `driver-top3 task`\n",
    "dataset, task, train_table, val_table, test_table = initialize_task(\n",
    "    \"rel-f1\", \"driver-top3\"\n",
    ")\n",
    "db, col_to_stype_dict = db_to_graph(dataset)\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,\n",
    "    text_embedder_cfg=text_embedder_cfg,\n",
    "    cache_dir=os.path.join(root_dir, f\"rel-f1_materialized_cache\"),\n",
    ")\n",
    "\n",
    "loader_dict, entity_table = get_loader(train_table, val_table, test_table, task, data)\n",
    "model = RDLModel(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "eval_model(model, loader_dict, \"test\", task, device, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, trying out our model zero-shot does not yield amazing results. However, what happens if we use this model as a starting point for finetuning on the task? Let's experiment on fine-tuning this model with fewer epochs on the `driver-top3` task and checking its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 1.3057963123871323, Val metrics: {'average_precision': np.float64(0.14596141016259206), 'accuracy': 0.7670068027210885, 'f1': np.float64(0.014388489208633094), 'roc_auc': np.float64(0.3403450932611851)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.492364590069319, Val metrics: {'average_precision': np.float64(0.147660166536003), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.3480317500134382)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.4756998234295616, Val metrics: {'average_precision': np.float64(0.18617978634488963), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.5037358226872839)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.457907124307538, Val metrics: {'average_precision': np.float64(0.24818470383417085), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.6028202325706402)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.449112638555803, Val metrics: {'average_precision': np.float64(0.2582261868388357), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.6171722420311408)}\n",
      "Best val metrics: {'average_precision': np.float64(0.25844071115123446), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.617208077260755)}\n",
      "Best test metrics: {'average_precision': np.float64(0.2731415142474485), 'accuracy': 0.8236914600550964, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.7204157086120402)}\n"
     ]
    }
   ],
   "source": [
    "# Get model after a training run\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "state_dict = training_run(\n",
    "    model,\n",
    "    device,\n",
    "    optimizer,\n",
    "    task,\n",
    "    loader_dict,\n",
    "    val_table,\n",
    "    loss_fn,\n",
    "    entity_table,\n",
    "    epochs=5,\n",
    "    state_dict=state_dict,\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Evaluate on val and test set\n",
    "eval_model(model, loader_dict, \"val\", task, device, val_table)\n",
    "eval_model(model, loader_dict, \"test\", task, device, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! It looks like after we finetune even after just one epoch. we're able to practically replicate the Relbench results. Finally, let's compare this approach to simply training on the task from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.6766921718386659, Val metrics: {'average_precision': np.float64(0.22167779641641927), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.588683234487825)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.4552399510819209, Val metrics: {'average_precision': np.float64(0.22607865741856337), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.5989141925426887)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.4486066358052442, Val metrics: {'average_precision': np.float64(0.22778145495906807), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.5990575334611457)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.4420464193917871, Val metrics: {'average_precision': np.float64(0.23657871893378135), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.6117252871297773)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.43975554136814055, Val metrics: {'average_precision': np.float64(0.28826219978742496), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.6088584687606386)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.43636006828334184, Val metrics: {'average_precision': np.float64(0.31479855414086527), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.629159126337102)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.43033227553564973, Val metrics: {'average_precision': np.float64(0.331351335742997), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.6592248839834441)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.4114072441570158, Val metrics: {'average_precision': np.float64(0.3600801816641911), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.711920589131175)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.3698024127497465, Val metrics: {'average_precision': np.float64(0.4190964469924286), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.755173711275555)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.36252130260752996, Val metrics: {'average_precision': np.float64(0.37695138254729166), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.74582071634624)}\n",
      "Best val metrics: {'average_precision': np.float64(0.4188869101747401), 'accuracy': 0.7976190476190477, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.7550841232015195)}\n",
      "Best test metrics: {'average_precision': np.float64(0.33543511977785767), 'accuracy': 0.8236914600550964, 'f1': np.float64(0.0), 'roc_auc': np.float64(0.787860576923077)}\n"
     ]
    }
   ],
   "source": [
    "# Define a new model, don't load in old weights.\n",
    "base_model = RDLModel(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "base_optimizer = torch.optim.Adam(base_model.parameters(), lr=0.005)\n",
    "base_state_dict = training_run(\n",
    "    base_model,\n",
    "    device,\n",
    "    base_optimizer,\n",
    "    task,\n",
    "    loader_dict,\n",
    "    val_table,\n",
    "    loss_fn,\n",
    "    entity_table,\n",
    "    epochs=10,\n",
    ")\n",
    "base_model.load_state_dict(base_state_dict)\n",
    "\n",
    "# Evaluate on val and test set\n",
    "eval_model(base_model, loader_dict, \"val\", task, device, val_table)\n",
    "eval_model(base_model, loader_dict, \"test\", task, device, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we don't see much of a difference from starting from random weights to using a model pre-initialized from another entity classification task.\n",
    "\n",
    "### Challenge\n",
    "Does this trend necessarily work on larger and more diverse datasets? Depending on your compute availability, try out using different datasets, like `rel-amazon`, as well as across different types of tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Different expressiveness of node features?\n",
    "Next, let's take a look at using different embedding models for node features.\n",
    "\n",
    "The embedding models are used to help turn the tabular data into usable node features. In the Relbench tutorial, the team uses GloVe embeddings, but the paper also mentions utilizing BERT-style embeddings. In traditional NLP, BERT embeddings are much more popular given that they are contextual -- the vector representation depends on the surrounding words, compared to static embeddings used by GloVe -- and can handle words outside of their vocabulary. In addition, their embedding size is $768$ compared to GloVe's $300$, which introduces an opportunity for more expressiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an investigation, let's switch out our GloVe embedding model with BERT and retrain a new model from scratch on the `driver-dnf` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with mean pooling.\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/cpondoc/classes/cs224w/project/env/lib/python3.9/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "100%|██████████| 23/23 [00:02<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.38312724910414653, Val metrics: {'average_precision': np.float64(0.8345221417962831), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.5930340136054422)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.3540534934752266, Val metrics: {'average_precision': np.float64(0.8473015448671046), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.6246530612244898)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.3357846071938254, Val metrics: {'average_precision': np.float64(0.8905183265671703), 'accuracy': 0.7491166077738516, 'f1': np.float64(0.8476394849785408), 'roc_auc': np.float64(0.6827029478458049)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.3116109115942032, Val metrics: {'average_precision': np.float64(0.8965321535022579), 'accuracy': 0.6607773851590106, 'f1': np.float64(0.7664233576642335), 'roc_auc': np.float64(0.687201814058957)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.30605150242752743, Val metrics: {'average_precision': np.float64(0.8985108863522302), 'accuracy': 0.696113074204947, 'f1': np.float64(0.7971698113207547), 'roc_auc': np.float64(0.697342403628118)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.3026287253466489, Val metrics: {'average_precision': np.float64(0.9018481327312416), 'accuracy': 0.7491166077738516, 'f1': np.float64(0.8517745302713987), 'roc_auc': np.float64(0.6974149659863945)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.2972710859361847, Val metrics: {'average_precision': np.float64(0.900533309282381), 'accuracy': 0.7402826855123675, 'f1': np.float64(0.8368479467258602), 'roc_auc': np.float64(0.7018231292517008)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.2959926546941494, Val metrics: {'average_precision': np.float64(0.9012056339689314), 'accuracy': 0.7614840989399293, 'f1': np.float64(0.8524590163934426), 'roc_auc': np.float64(0.7092607709750567)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.2905985877021002, Val metrics: {'average_precision': np.float64(0.9032973199191973), 'accuracy': 0.7526501766784452, 'f1': np.float64(0.8409090909090909), 'roc_auc': np.float64(0.7175328798185941)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.2868953991673829, Val metrics: {'average_precision': np.float64(0.9080292417308474), 'accuracy': 0.7067137809187279, 'f1': np.float64(0.7995169082125604), 'roc_auc': np.float64(0.7248616780045352)}\n",
      "Best val metrics: {'average_precision': np.float64(0.9080472407878784), 'accuracy': 0.7067137809187279, 'f1': np.float64(0.7995169082125604), 'roc_auc': np.float64(0.7248979591836734)}\n",
      "Best test metrics: {'average_precision': np.float64(0.84692732763889), 'accuracy': 0.7222222222222222, 'f1': np.float64(0.7940865892291447), 'roc_auc': np.float64(0.731849899965842)}\n"
     ]
    }
   ],
   "source": [
    "from src.embeddings.bert import BertTextEmbedding\n",
    "\n",
    "dataset, task, train_table, val_table, test_table = initialize_task(\n",
    "    \"rel-f1\", \"driver-dnf\"\n",
    ")\n",
    "\n",
    "# Preprocess the database data and set up our text embedder\n",
    "db, col_to_stype_dict = db_to_graph(dataset)\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=BertTextEmbedding(device=device), batch_size=128\n",
    ")\n",
    "\n",
    "# Load in data used to train model\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,\n",
    "    text_embedder_cfg=text_embedder_cfg,\n",
    "    cache_dir=os.path.join(root_dir, f\"rel-f1_materialized_cache\"),\n",
    ")\n",
    "loader_dict, entity_table = get_loader(train_table, val_table, test_table, task, data)\n",
    "\n",
    "# Initialize new, untrained model using BERT embeddings\n",
    "bert_model = RDLModel(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "bert_optimizer = torch.optim.Adam(bert_model.parameters(), lr=0.005)\n",
    "bert_state_dict = training_run(\n",
    "    bert_model,\n",
    "    device,\n",
    "    bert_optimizer,\n",
    "    task,\n",
    "    loader_dict,\n",
    "    val_table,\n",
    "    loss_fn,\n",
    "    entity_table,\n",
    "    epochs=10,\n",
    ")\n",
    "bert_model.load_state_dict(bert_state_dict)\n",
    "\n",
    "# Evaluate on val and test set\n",
    "eval_model(bert_model, loader_dict, \"val\", task, device, val_table)\n",
    "eval_model(bert_model, loader_dict, \"test\", task, device, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ultimately don't see that drastic of a difference between using BERT embeddings and GloVe embeddings. Despite being trained differently, the fact that the models are close in size and perform similarly on [general embedding benchmarks](https://huggingface.co/spaces/mteb/leaderboard) may suggest that the results will not be that drastic. \n",
    "\n",
    "### Challenge\n",
    "We encourage you to try larger models with even larger embedding dimensions -- to do so, use our `CustomTextEmbedding` class! To use this class, import it as below, and then specify the name of a model as used on HuggingFace:\n",
    "\n",
    "```python\n",
    "from src.embeddings.custom import CustomTextEmbedding\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=CustomTextEmbedding(model_name=<INSERT_HUGGINGFACE_MODEL_HERE>, device=device), batch_size=128\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Different RDL model architectures?\n",
    "Finally, we experiment with different RDL model architectures. In particular, we investigate what happens as we add or subtract GNN layers from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we double the number of GNN layers in our RDL pipeline, moving from `num_layers=2` to `num_layers=4`. The idea is that by adding more layers, we can create a more expressive network that can understand more complex relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.37630944748345185, Val metrics: {'average_precision': np.float64(0.8354548486707016), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.584453514739229)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.35387199274831915, Val metrics: {'average_precision': np.float64(0.8368606888184498), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.5990204081632653)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.35184785197424895, Val metrics: {'average_precision': np.float64(0.8451311245963857), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.614766439909297)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.3307221185266789, Val metrics: {'average_precision': np.float64(0.88688278486892), 'accuracy': 0.7279151943462897, 'f1': np.float64(0.8378947368421052), 'roc_auc': np.float64(0.6512834467120181)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.31274610553330184, Val metrics: {'average_precision': np.float64(0.8841466762743575), 'accuracy': 0.7120141342756183, 'f1': np.float64(0.8190899001109878), 'roc_auc': np.float64(0.6808344671201814)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.3114925918194866, Val metrics: {'average_precision': np.float64(0.8896977751836486), 'accuracy': 0.7049469964664311, 'f1': np.float64(0.8138238573021181), 'roc_auc': np.float64(0.6868208616780045)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.30794541325559543, Val metrics: {'average_precision': np.float64(0.888868560924413), 'accuracy': 0.7014134275618374, 'f1': np.float64(0.8072976054732041), 'roc_auc': np.float64(0.6837913832199546)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.3053583731634382, Val metrics: {'average_precision': np.float64(0.8928719671015126), 'accuracy': 0.7102473498233216, 'f1': np.float64(0.8144796380090498), 'roc_auc': np.float64(0.6915374149659864)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.305654157629858, Val metrics: {'average_precision': np.float64(0.8915923514845823), 'accuracy': 0.7402826855123675, 'f1': np.float64(0.842443729903537), 'roc_auc': np.float64(0.690485260770975)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.3016997343055749, Val metrics: {'average_precision': np.float64(0.9017659218757775), 'accuracy': 0.7420494699646644, 'f1': np.float64(0.8459915611814346), 'roc_auc': np.float64(0.7103673469387755)}\n",
      "Best val metrics: {'average_precision': np.float64(0.9016887622946698), 'accuracy': 0.7420494699646644, 'f1': np.float64(0.8459915611814346), 'roc_auc': np.float64(0.7101133786848073)}\n",
      "Best test metrics: {'average_precision': np.float64(0.8500868239437355), 'accuracy': 0.7236467236467237, 'f1': np.float64(0.8239564428312159), 'roc_auc': np.float64(0.7235592641389743)}\n"
     ]
    }
   ],
   "source": [
    "# Define a new model, don't load in old weights.\n",
    "deep_model = RDLModel(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=4,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "deep_optimizer = torch.optim.Adam(deep_model.parameters(), lr=0.005)\n",
    "deep_state_dict = training_run(\n",
    "    deep_model,\n",
    "    device,\n",
    "    deep_optimizer,\n",
    "    task,\n",
    "    loader_dict,\n",
    "    val_table,\n",
    "    loss_fn,\n",
    "    entity_table,\n",
    "    epochs=10,\n",
    ")\n",
    "deep_model.load_state_dict(deep_state_dict)\n",
    "\n",
    "# Evaluate on val and test set\n",
    "eval_model(deep_model, loader_dict, \"val\", task, device, val_table)\n",
    "eval_model(deep_model, loader_dict, \"test\", task, device, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, training using $4$ layers actually makes the model perform worse over time. Thus, given the simplicity of the task and the size of dataset, it is likely that we are overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that using double the amount of layers leads to less optimal results, we can try the opposite strategy and halve the number of layers in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.36102279100344126, Val metrics: {'average_precision': np.float64(0.8693253390608777), 'accuracy': 0.7544169611307421, 'f1': np.float64(0.8544502617801047), 'roc_auc': np.float64(0.6637460317460318)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.3243081846461581, Val metrics: {'average_precision': np.float64(0.8885520335913858), 'accuracy': 0.6908127208480566, 'f1': np.float64(0.7943595769682726), 'roc_auc': np.float64(0.6762811791383221)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.3095765669996069, Val metrics: {'average_precision': np.float64(0.8982087752254366), 'accuracy': 0.726148409893993, 'f1': np.float64(0.8324324324324325), 'roc_auc': np.float64(0.695219954648526)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.30494005722550777, Val metrics: {'average_precision': np.float64(0.9013646492474375), 'accuracy': 0.7084805653710248, 'f1': np.float64(0.8096885813148789), 'roc_auc': np.float64(0.7025850340136055)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.3002260228185271, Val metrics: {'average_precision': np.float64(0.9037170583963824), 'accuracy': 0.7014134275618374, 'f1': np.float64(0.8037166085946573), 'roc_auc': np.float64(0.7048526077097506)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.29445440567727577, Val metrics: {'average_precision': np.float64(0.9013048280403471), 'accuracy': 0.7685512367491166, 'f1': np.float64(0.8659160696008188), 'roc_auc': np.float64(0.7074648526077097)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.29507051193476996, Val metrics: {'average_precision': np.float64(0.9016249706950684), 'accuracy': 0.6802120141342756, 'f1': np.float64(0.7757125154894672), 'roc_auc': np.float64(0.7034195011337868)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.290469367433499, Val metrics: {'average_precision': np.float64(0.9050141416982755), 'accuracy': 0.715547703180212, 'f1': np.float64(0.8151549942594719), 'roc_auc': np.float64(0.7138866213151928)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.2851247564278104, Val metrics: {'average_precision': np.float64(0.9042633733935974), 'accuracy': 0.7226148409893993, 'f1': np.float64(0.8205714285714286), 'roc_auc': np.float64(0.7125260770975057)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.2823277630630775, Val metrics: {'average_precision': np.float64(0.9052831608611303), 'accuracy': 0.7208480565371025, 'f1': np.float64(0.8240534521158129), 'roc_auc': np.float64(0.7118185941043083)}\n",
      "Best val metrics: {'average_precision': np.float64(0.9050579385447367), 'accuracy': 0.715547703180212, 'f1': np.float64(0.8151549942594719), 'roc_auc': np.float64(0.7141224489795919)}\n",
      "Best test metrics: {'average_precision': np.float64(0.8425754218954633), 'accuracy': 0.7193732193732194, 'f1': np.float64(0.8170844939647168), 'roc_auc': np.float64(0.6876982384228763)}\n"
     ]
    }
   ],
   "source": [
    "# Define a new model, don't load in old weights.\n",
    "shallow_model = RDLModel(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=1,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "shallow_optimizer = torch.optim.Adam(shallow_model.parameters(), lr=0.005)\n",
    "shallow_state_dict = training_run(\n",
    "    shallow_model,\n",
    "    device,\n",
    "    shallow_optimizer,\n",
    "    task,\n",
    "    loader_dict,\n",
    "    val_table,\n",
    "    loss_fn,\n",
    "    entity_table,\n",
    "    epochs=10,\n",
    ")\n",
    "shallow_model.load_state_dict(shallow_state_dict)\n",
    "\n",
    "# Evaluate on val and test set\n",
    "eval_model(shallow_model, loader_dict, \"val\", task, device, val_table)\n",
    "eval_model(shallow_model, loader_dict, \"test\", task, device, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, we see that even with half the number of layers, we do just about the same as with double the number of layers. Once again, this might be more task-specific as opposed to a general conclusion about GNNs and the RDL pipeline.\n",
    "\n",
    "### Challenge\n",
    "Does this trend necessarily hold on larger and more diverse datasets? Depending on your compute availability, try out using different datasets, like `rel-amazon`, as well as across different types of tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: What about different graph layers?\n",
    "We can also just try using different graph layers, featured in PyG. Below is GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.38052082677610854, Val metrics: {'average_precision': np.float64(0.8433403727188312), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.6251519274376416)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.3574965990803618, Val metrics: {'average_precision': np.float64(0.8825352397919566), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.69340589569161)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.32906677605978146, Val metrics: {'average_precision': np.float64(0.8893162726600771), 'accuracy': 0.7791519434628975, 'f1': np.float64(0.8758689175769613), 'roc_auc': np.float64(0.6743854875283447)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.3092604429848657, Val metrics: {'average_precision': np.float64(0.8976818695773845), 'accuracy': 0.7526501766784452, 'f1': np.float64(0.855072463768116), 'roc_auc': np.float64(0.7134512471655329)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.29846293777005406, Val metrics: {'average_precision': np.float64(0.9036445197945777), 'accuracy': 0.7544169611307421, 'f1': np.float64(0.8500539374325782), 'roc_auc': np.float64(0.7290158730158729)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.2910831387073713, Val metrics: {'average_precision': np.float64(0.883193775163816), 'accuracy': 0.7579505300353356, 'f1': np.float64(0.8448471121177803), 'roc_auc': np.float64(0.693451247165533)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.2870623269425654, Val metrics: {'average_precision': np.float64(0.8861264658904081), 'accuracy': 0.7614840989399293, 'f1': np.float64(0.8488241881298992), 'roc_auc': np.float64(0.695655328798186)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.28393651492160454, Val metrics: {'average_precision': np.float64(0.8972221333887909), 'accuracy': 0.7915194346289752, 'f1': np.float64(0.8739316239316239), 'roc_auc': np.float64(0.7205442176870749)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.28227804249002203, Val metrics: {'average_precision': np.float64(0.8912351066454262), 'accuracy': 0.765017667844523, 'f1': np.float64(0.8533627342888643), 'roc_auc': np.float64(0.7075736961451247)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.2759197559206045, Val metrics: {'average_precision': np.float64(0.8906311165803125), 'accuracy': 0.7809187279151943, 'f1': np.float64(0.8655097613882863), 'roc_auc': np.float64(0.704843537414966)}\n",
      "Best val metrics: {'average_precision': np.float64(0.9036447759347126), 'accuracy': 0.7544169611307421, 'f1': np.float64(0.8500539374325782), 'roc_auc': np.float64(0.729015873015873)}\n",
      "Best test metrics: {'average_precision': np.float64(0.8237305452344359), 'accuracy': 0.6709401709401709, 'f1': np.float64(0.780209324452902), 'roc_auc': np.float64(0.6854047723612942)}\n"
     ]
    }
   ],
   "source": [
    "# Define a new model, don't load in old weights.\n",
    "from src.models.rdl.gat import RDLGATModel\n",
    "gcn_model = RDLGATModel(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "gcn_optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.005)\n",
    "gcn_state_dict = training_run(\n",
    "    gcn_model,\n",
    "    device,\n",
    "    gcn_optimizer,\n",
    "    task,\n",
    "    loader_dict,\n",
    "    val_table,\n",
    "    loss_fn,\n",
    "    entity_table,\n",
    "    epochs=10,\n",
    ")\n",
    "gcn_model.load_state_dict(gcn_state_dict)\n",
    "\n",
    "# Evaluate on val and test set\n",
    "eval_model(gcn_model, loader_dict, \"val\", task, device, val_table)\n",
    "eval_model(gcn_model, loader_dict, \"test\", task, device, None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZLbeQ8nLws8bu/8tbPPMT",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
